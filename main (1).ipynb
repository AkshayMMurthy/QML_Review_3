{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import socket\n",
    "import struct\n",
    "import pennylane as qml\n",
    "import base64\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                            ExtraTreesClassifier, GradientBoostingClassifier)\n",
    "# from lightgbm import LGBMClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275528, 21)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"CSV/TestbedSunJun13Flows.csv\")\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 275528 entries, 0 to 275527\n",
      "Data columns (total 21 columns):\n",
      " #   Column                          Non-Null Count   Dtype \n",
      "---  ------                          --------------   ----- \n",
      " 0   generated                       275528 non-null  object\n",
      " 1   appName                         275528 non-null  object\n",
      " 2   totalSourceBytes                275528 non-null  int64 \n",
      " 3   totalDestinationBytes           275528 non-null  int64 \n",
      " 4   totalDestinationPackets         275528 non-null  int64 \n",
      " 5   totalSourcePackets              275528 non-null  int64 \n",
      " 6   sourcePayloadAsBase64           123604 non-null  object\n",
      " 7   sourcePayloadAsUTF              123388 non-null  object\n",
      " 8   destinationPayloadAsBase64      118724 non-null  object\n",
      " 9   destinationPayloadAsUTF         118696 non-null  object\n",
      " 10  direction                       275528 non-null  object\n",
      " 11  sourceTCPFlagsDescription       220704 non-null  object\n",
      " 12  destinationTCPFlagsDescription  213038 non-null  object\n",
      " 13  source                          275528 non-null  object\n",
      " 14  protocolName                    275528 non-null  object\n",
      " 15  sourcePort                      275528 non-null  int64 \n",
      " 16  destination                     275528 non-null  object\n",
      " 17  destinationPort                 275528 non-null  int64 \n",
      " 18  startDateTime                   275528 non-null  object\n",
      " 19  stopDateTime                    275528 non-null  object\n",
      " 20  Label                           275528 non-null  object\n",
      "dtypes: int64(6), object(15)\n",
      "memory usage: 44.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop payload columns\n",
    "payload_columns = [\n",
    "    \"sourcePayloadAsBase64\", \"sourcePayloadAsUTF\",\n",
    "    \"destinationPayloadAsBase64\", \"destinationPayloadAsUTF\"\n",
    "]\n",
    "df.drop(columns=payload_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels\n",
    "df[\"Label\"] = df[\"Label\"].map({\"Normal\": 0, \"Attack\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.utils import resample\n",
    "\n",
    "# def undersample_dataset(df, class_column):\n",
    "#     \"\"\"\n",
    "#     Undersample the majority classes to match the minority class size.\n",
    "    \n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     df : pandas.DataFrame\n",
    "#         The imbalanced dataset\n",
    "#     class_column : str\n",
    "#         The name of the column containing class labels\n",
    "        \n",
    "#     Returns:\n",
    "#     --------\n",
    "#     pandas.DataFrame\n",
    "#         The balanced dataset\n",
    "#     \"\"\"\n",
    "#     # Get the class distribution\n",
    "#     class_counts = df[class_column].value_counts()\n",
    "    \n",
    "#     # Find the minority class and its count\n",
    "#     minority_class = class_counts.idxmin()\n",
    "#     minority_count = class_counts.min()\n",
    "    \n",
    "#     print(f\"Minority class: {minority_class} with {minority_count} samples\")\n",
    "    \n",
    "#     # Create a list to store the balanced data\n",
    "#     balanced_dfs = []\n",
    "    \n",
    "#     # Add all samples from the minority class\n",
    "#     minority_df = df[df[class_column] == minority_class]\n",
    "#     balanced_dfs.append(minority_df)\n",
    "    \n",
    "#     # Undersample each majority class\n",
    "#     for cls in class_counts.index:\n",
    "#         if cls != minority_class:\n",
    "#             # Get all samples from this class\n",
    "#             class_df = df[df[class_column] == cls]\n",
    "#             # Undersample to match minority class size\n",
    "#             undersampled_df = resample(class_df, \n",
    "#                                       replace=False,  # sample without replacement\n",
    "#                                       n_samples=minority_count,  # match minority class\n",
    "#                                       random_state=42)  # reproducible results\n",
    "#             balanced_dfs.append(undersampled_df)\n",
    "    \n",
    "#     # Combine all balanced classes\n",
    "#     balanced_df = pd.concat(balanced_dfs)\n",
    "    \n",
    "#     # Shuffle the dataset\n",
    "#     balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "#     print(f\"Original dataset shape: {df.shape}\")\n",
    "#     print(f\"Balanced dataset shape: {balanced_df.shape}\")\n",
    "#     print(\"New class distribution:\")\n",
    "#     print(balanced_df[class_column].value_counts())\n",
    "    \n",
    "#     return balanced_df\n",
    "\n",
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     # Print original class distribution\n",
    "#     print(\"Original class distribution:\")\n",
    "#     print(df['Label'].value_counts())\n",
    "    \n",
    "#     # Undersample to balance the dataset\n",
    "#     balanced_df = undersample_dataset(df, 'Label')\n",
    "#     df = balanced_df\n",
    "#     # Save the balanced dataset if needed\n",
    "#     # balanced_df.to_csv('balanced_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "0    255170\n",
      "1     20358\n",
      "Name: count, dtype: int64\n",
      "Label\n",
      "1    100\n",
      "0    100\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "# Check the unique counts in the label column\n",
    "print(df['Label'].value_counts())\n",
    "\n",
    "# Separate classes\n",
    "class_counts = df['Label'].value_counts()\n",
    "minority_class = class_counts.idxmin()  # Class with fewer samples\n",
    "majority_class = class_counts.idxmax()  # Class with more samples\n",
    "\n",
    "df_minority = df[df['Label'] == minority_class]\n",
    "df_majority = df[df['Label'] == majority_class]\n",
    "\n",
    "# Undersample both classes to 70 records each\n",
    "df_minority_undersampled = resample(df_minority, \n",
    "                                    replace=False, \n",
    "                                    n_samples=100, \n",
    "                                    random_state=46)\n",
    "\n",
    "df_majority_undersampled = resample(df_majority, \n",
    "                                    replace=False, \n",
    "                                    n_samples=100, \n",
    "                                    random_state=48)\n",
    "\n",
    "# Combine the undersampled data\n",
    "df_balanced = pd.concat([df_minority_undersampled, df_majority_undersampled])\n",
    "\n",
    "# Shuffle the dataset to mix the classes\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Check new class distribution\n",
    "print(df_balanced['Label'].value_counts())\n",
    "\n",
    "\n",
    "df = df_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 17 columns):\n",
      " #   Column                          Non-Null Count  Dtype \n",
      "---  ------                          --------------  ----- \n",
      " 0   generated                       200 non-null    object\n",
      " 1   appName                         200 non-null    object\n",
      " 2   totalSourceBytes                200 non-null    int64 \n",
      " 3   totalDestinationBytes           200 non-null    int64 \n",
      " 4   totalDestinationPackets         200 non-null    int64 \n",
      " 5   totalSourcePackets              200 non-null    int64 \n",
      " 6   direction                       200 non-null    object\n",
      " 7   sourceTCPFlagsDescription       177 non-null    object\n",
      " 8   destinationTCPFlagsDescription  170 non-null    object\n",
      " 9   source                          200 non-null    object\n",
      " 10  protocolName                    200 non-null    object\n",
      " 11  sourcePort                      200 non-null    int64 \n",
      " 12  destination                     200 non-null    object\n",
      " 13  destinationPort                 200 non-null    int64 \n",
      " 14  startDateTime                   200 non-null    object\n",
      " 15  stopDateTime                    200 non-null    object\n",
      " 16  Label                           200 non-null    int64 \n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 26.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric features\n",
    "numeric_cols = df.select_dtypes(include=['int64']).columns\n",
    "X = df[numeric_cols].drop(columns=\"Label\")\n",
    "y = df['Label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pennylane as qml\n",
    "# n_features = X.shape[1]\n",
    "# N = int(np.ceil(np.log2(n_features)))\n",
    "# wires = range(N)\n",
    "# dev = qml.device('lightning.qubit', wires)    \n",
    "\n",
    "# @qml.qnode(dev)\n",
    "# def circuit(f=None):\n",
    "#     qml.AmplitudeEmbedding(f, wires=wires,pad_with=0,normalize=True)\n",
    "#     return qml.state()\n",
    "# X_norm = X.values\n",
    "# X_quantum = circuit(X_norm)\n",
    "# X_real = np.real(np.array(X_quantum))\n",
    "# # Create column names based on index\n",
    "# column_names = [f'feature_{i}' for i in range(X_real.shape[1])]\n",
    "# X_real = pd.DataFrame(X_real, columns=column_names)\n",
    "\n",
    "# X = X_real\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pennylane as qml\n",
    "# from pennylane import numpy as np\n",
    "\n",
    "# N = X.shape[1]\n",
    "# wires = range(N)\n",
    "# dev = qml.device(\"default.qubit\", wires)\n",
    "\n",
    "# @qml.qnode(dev)\n",
    "# def circuit(val_list):\n",
    "#     qml.AngleEmbedding(val_list, wires, rotation=\"Y\")\n",
    "#     return [qml.expval(qml.PauliZ(w)) for w in wires]\n",
    "\n",
    "# # Function to process DataFrame through quantum circuit\n",
    "# def quantum_transform(df):\n",
    "#     # Convert DataFrame to numpy array\n",
    "#     values = df.values\n",
    "#     # Process each row through quantum circuit\n",
    "#     quantum_features = np.array([circuit(row) for row in values])\n",
    "#     # Remove tensor properties and convert to regular numpy array\n",
    "#     quantum_features = np.array(quantum_features).astype(float)\n",
    "#     return quantum_features\n",
    "# # Transform your data\n",
    "# X_real = quantum_transform(X)\n",
    "\n",
    "# quantum_cols = [f'quantum_state_{i}' for i in range(len(X_real[0]))]\n",
    "# X_real = pd.DataFrame(X_real, columns=quantum_cols)\n",
    "# X_real.head()\n",
    "# X = X_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # Fit the scaler on the training data and transform it\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# # Transform the test data using the same scaler\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: SVM (Linear)\n",
      "Evaluating model: SVM (Poly)\n",
      "Evaluating model: SVM (RBF)\n",
      "Evaluating model: SVM (Sigmoid)\n",
      "  Model  Accuracy  Precision   Recall  F1 Score ROC AUC  Cohen’s Kappa  \\\n",
      "0   SVC  0.900000   0.882353  0.93750  0.909091    None       0.798206   \n",
      "1   SVC  0.716667   0.826087  0.59375  0.690909    None       0.442013   \n",
      "2   SVC  0.900000   0.882353  0.93750  0.909091    None       0.798206   \n",
      "3   SVC  0.900000   0.882353  0.93750  0.909091    None       0.798206   \n",
      "\n",
      "   Running Time (s)  \n",
      "0        182.950845  \n",
      "1          0.008114  \n",
      "2          0.007639  \n",
      "3          0.007912  \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, cohen_kappa_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import xgboost as xgb\n",
    "# import lightgbm as lgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Create a dictionary of models to evaluate\n",
    "models = {\n",
    "    \"SVM (Linear)\": SVC(kernel=\"linear\", random_state=42),\n",
    "    \"SVM (Poly)\": SVC(kernel=\"poly\", random_state=42),\n",
    "    \"SVM (RBF)\": SVC(kernel=\"rbf\", random_state=42),\n",
    "    \"SVM (Sigmoid)\": SVC(kernel=\"sigmoid\", random_state=42),\n",
    "    # \"KNN\": KNeighborsClassifier(),\n",
    "    # \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    # \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
    "    # \"Extra Trees\": ExtraTreesClassifier(n_estimators=100, random_state=42),\n",
    "    # \"XGBoost\": xgb.XGBClassifier(random_state=42),\n",
    "    # \"LightGBM\": lgb.LGBMClassifier(random_state=42),\n",
    "    # \"Gradient Boosting\": GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Function to calculate metrics\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    start_time = time.time()  # Track model fitting time\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "\n",
    "    # Get performance metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_proba) if y_proba is not None else None\n",
    "    cohen_kappa = cohen_kappa_score(y_test, y_pred)\n",
    "    \n",
    "    # Running time\n",
    "    end_time = time.time()\n",
    "    runtime = end_time - start_time\n",
    "    \n",
    "    # Detailed classification report\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    \n",
    "    # Return all metrics\n",
    "    return {\n",
    "        \"Model\": model.__class__.__name__,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1,\n",
    "        \"ROC AUC\": roc_auc,\n",
    "        \"Cohen’s Kappa\": cohen_kappa,\n",
    "        \"Running Time (s)\": runtime,\n",
    "    }\n",
    "\n",
    "# Evaluating all models and storing results\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Evaluating model: {name}\")\n",
    "    result = evaluate_model(model, X_train, X_test, y_train, y_test)\n",
    "    results.append(result)\n",
    "\n",
    "# Convert results into a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display all the results\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df.to_csv('TestbedThuJun17Flows_ang.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Recall",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F1 Score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ROC AUC",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Cohen’s Kappa",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Running Time (s)",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "413b7c21-8af7-43d3-aba1-f4293123b718",
       "rows": [
        [
         "0",
         "SVC",
         "0.9",
         "0.8823529411764706",
         "0.9375",
         "0.9090909090909091",
         null,
         "0.7982062780269058",
         "182.95084500312805"
        ],
        [
         "1",
         "SVC",
         "0.7166666666666667",
         "0.8260869565217391",
         "0.59375",
         "0.6909090909090909",
         null,
         "0.4420131291028446",
         "0.008113861083984375"
        ],
        [
         "2",
         "SVC",
         "0.9",
         "0.8823529411764706",
         "0.9375",
         "0.9090909090909091",
         null,
         "0.7982062780269058",
         "0.007639169692993164"
        ],
        [
         "3",
         "SVC",
         "0.9",
         "0.8823529411764706",
         "0.9375",
         "0.9090909090909091",
         null,
         "0.7982062780269058",
         "0.00791168212890625"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>Cohen’s Kappa</th>\n",
       "      <th>Running Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.93750</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>None</td>\n",
       "      <td>0.798206</td>\n",
       "      <td>182.950845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.59375</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>None</td>\n",
       "      <td>0.442013</td>\n",
       "      <td>0.008114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.93750</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>None</td>\n",
       "      <td>0.798206</td>\n",
       "      <td>0.007639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.93750</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>None</td>\n",
       "      <td>0.798206</td>\n",
       "      <td>0.007912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Accuracy  Precision   Recall  F1 Score ROC AUC  Cohen’s Kappa  \\\n",
       "0   SVC  0.900000   0.882353  0.93750  0.909091    None       0.798206   \n",
       "1   SVC  0.716667   0.826087  0.59375  0.690909    None       0.442013   \n",
       "2   SVC  0.900000   0.882353  0.93750  0.909091    None       0.798206   \n",
       "3   SVC  0.900000   0.882353  0.93750  0.909091    None       0.798206   \n",
       "\n",
       "   Running Time (s)  \n",
       "0        182.950845  \n",
       "1          0.008114  \n",
       "2          0.007639  \n",
       "3          0.007912  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 100, 1: 100}\n",
      "Label\n",
      "1    100\n",
      "0    100\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Method 1: Using numpy unique with return_counts\n",
    "unique_values, counts = np.unique(y, return_counts=True)\n",
    "print(dict(zip(unique_values, counts)))\n",
    "\n",
    "# Method 2: Using value_counts if y is a pandas series\n",
    "print(pd.Series(y).value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_env_latest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
